# Teams Meeting Coach

ğŸ¯ **Real-time AI coaching for Microsoft Teams meetings**

A powerful real-time meeting feedback system that captures Teams audio, transcribes speech, and provides live coaching on speaking pace, tone, and communication effectiveness.

## âœ¨ Features

- **ğŸ¤ Live Audio Capture**: Captures Teams audio via BlackHole virtual audio device
- **ğŸ“ Real-time Transcription**: Uses Faster-Whisper for streaming speech-to-text
- **â±ï¸ Speaking Pace Analysis**: Monitors words per minute with smart alerts
- **ğŸ­ Tone Detection**: AI-powered analysis of communication style and sentiment
- **ğŸ”„ Filler Word Tracking**: Counts and reports usage of "um", "uh", "like", etc.
- **ğŸ“Š Live Feedback Display**: Clean menu bar app or console interface
- **ğŸ¤– Local AI Processing**: Uses Ollama for private, offline tone analysis

## ğŸš€ Quick Start

### Automated Installation (Recommended)

```bash
git clone <your-repo>
cd teams-meeting-coach
chmod +x install_deps.sh
./install_deps.sh
```

This script will:
- Install BlackHole audio driver
- Install Ollama and download the LLM model
- Set up Python virtual environment
- Install all dependencies
- Run setup verification

### Manual Installation

1. **Install System Dependencies**
   ```bash
   # Install BlackHole audio driver
   brew install blackhole-2ch

   # Install Ollama for AI analysis
   brew install ollama
   ```

2. **Set Up Python Environment**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. **Configure Ollama**
   ```bash
   brew services start ollama
   ollama pull llama3
   ```

4. **Verify Setup**
   ```bash
   python setup_check.py
   ```

## ğŸµ Audio Configuration

**Critical**: You must configure audio routing for the coach to hear Teams audio:

1. **Open Audio MIDI Setup** (Applications â†’ Utilities)
2. **Create Multi-Output Device**: Click `+` â†’ "Create Multi-Output Device"
3. **Configure the Multi-Output**:
   - âœ… Check "BlackHole 2ch"
   - âœ… Check your speakers/headphones
   - Set drift correction if needed
4. **Configure Teams**:
   - Teams Settings â†’ Devices
   - Set **Speaker** to your Multi-Output Device
   - Keep **Microphone** as your preferred mic

This setup allows the coach to "listen" to Teams audio while you still hear everything normally.

## ğŸ® Usage

### Menu Bar App (Recommended)
```bash
./run_with_venv.sh
```

### Console Mode
```bash
./run_with_venv.sh --console
```

### Test Audio Setup
```bash
./run_with_venv.sh --test-audio
```

### Test Transcription
```bash
./run_with_venv.sh --test-transcription
```

## ğŸ“Š What You'll See

The coach provides real-time feedback on:

### Speaking Pace
- ğŸ¢ **Too Slow** (< 100 WPM): "Consider picking up the pace"
- âœ… **Ideal** (120-160 WPM): "Great pace!"
- ğŸ‡ **Too Fast** (> 180 WPM): "Try to slow down"

### Communication Tone
- ğŸ¤ **Supportive**: Collaborative and encouraging language
- ğŸ™„ **Dismissive**: Language that might shut down discussion
- ğŸ˜¤ **Aggressive**: Forceful or confrontational tone
- ğŸ˜ **Neutral**: Professional, matter-of-fact communication

### Filler Words
Real-time tracking of: "um", "uh", "like", "you know", "basically", "actually", "literally"

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# Audio settings
CHUNK_DURATION = 15          # Seconds per analysis chunk
WHISPER_MODEL = "base"       # Model size: tiny, base, small, medium, large

# Pace thresholds
PACE_TOO_FAST = 180         # Words per minute
PACE_TOO_SLOW = 100
PACE_IDEAL_MIN = 120
PACE_IDEAL_MAX = 160

# Analysis settings
MIN_WORDS_FOR_ANALYSIS = 10  # Minimum words before tone analysis
OLLAMA_MODEL = "llama3"      # LLM model for tone analysis
```

## ğŸ—ï¸ Architecture

```
Microsoft Teams Audio
          â†“
    BlackHole Driver
          â†“
     Audio Capture (PyAudio)
          â†“
    Faster-Whisper Transcription
          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
Pace Analysis  Filler Words  Tone Analysis
    â”‚             â”‚         (Ollama LLM)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
            Feedback Display
         (Menu Bar / Console)
```

## ğŸ§ª Testing

Run comprehensive tests:

```bash
# Test individual components
python test_transcription.py
python test_analyzer.py

# Test complete pipeline
python test_end_to_end.py

# Verify setup
python setup_check.py
```

## ğŸ› ï¸ Development Setup

This project uses a Python virtual environment and Make for task automation.

### Virtual Environment Configuration

The project includes automatic virtual environment detection through:

- **`.python-version`** - Specifies Python 3.12+ requirement (similar to `.nvmrc` for Node.js)
- **VS Code settings** (`.vscode/settings.json`) - Automatically activates venv in integrated terminal
- **Shell scripts** - `run_with_venv.sh` and `run_tests_venv.sh` handle activation
- **Make targets** - All Python commands automatically use the virtual environment

### Development Commands

Use Make for all development tasks:

```bash
# Install dependencies
make install

# Run tests
make test                # All tests
make test-unit          # Unit tests only
make test-integration   # Integration tests only
make test-fast          # Fast tests (no slow external deps)

# Code quality
make lint               # Linting
make format             # Code formatting

# Run demos
make run-demos          # All demonstration scripts
```

### Direct Virtual Environment Usage

If you need to run Python commands directly:

```bash
# Use the convenience scripts
./run_with_venv.sh python script.py
./run_tests_venv.sh test_module.py

# Or manually activate
source venv/bin/activate
python script.py
```

### Environment Files

- **`.python-version`** - Python version requirement (for pyenv, VS Code, etc.)
- **`requirements.txt`** - Python dependencies
- **`Makefile`** - Development task automation
- **`.vscode/settings.json`** - VS Code Python configuration

## ğŸ”§ Troubleshooting

### No Audio Captured
- **Check BlackHole**: Run `./run_with_venv.sh --test-audio`
- **Verify Teams Setup**: Ensure Teams speaker is set to Multi-Output Device
- **Check Permissions**: macOS may require microphone permissions

### Slow Transcription
- **Use Smaller Model**: Set `WHISPER_MODEL = "tiny"` in config.py
- **Increase Chunk Duration**: Set `CHUNK_DURATION = 20` in config.py
- **Use GPU**: Set `DEVICE = "cuda"` if available

### High CPU Usage
- **Optimize Whisper**: Set `COMPUTE_TYPE = "int8"` in config.py
- **Reduce Analysis Frequency**: Increase `MIN_WORDS_FOR_ANALYSIS`
- **Use Smaller LLM**: Try a smaller Ollama model

### Ollama Issues
```bash
# Restart Ollama service
brew services restart ollama

# Check available models
ollama list

# Re-download model if needed
ollama pull llama3
```

### Audio Device Issues
```bash
# List all audio devices
./run_with_venv.sh --test-audio

# Manually set device in config.py
BLACKHOLE_DEVICE_INDEX = 7  # Use index from test output
```

## ğŸ“ Project Structure

```
teams-meeting-coach/
â”œâ”€â”€ main.py              # Main application entry point
â”œâ”€â”€ audio_capture.py     # BlackHole audio capture
â”œâ”€â”€ transcriber.py       # Faster-Whisper integration
â”œâ”€â”€ analyzer.py          # Ollama tone analysis
â”œâ”€â”€ feedback_display.py  # Menu bar and console UI
â”œâ”€â”€ config.py           # Configuration settings
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ run_with_venv.sh    # Convenient runner script
â”œâ”€â”€ install_deps.sh     # Automated installation
â”œâ”€â”€ setup_check.py      # Setup verification
â””â”€â”€ test_*.py          # Test scripts
```

## ğŸ”’ Privacy & Security

- **Local Processing**: All analysis runs locally on your machine
- **No Cloud Services**: Audio never leaves your computer
- **No Data Storage**: Transcriptions are processed in real-time and discarded
- **Open Source**: Full code transparency

## ğŸ¯ Use Cases

- **Meeting Facilitation**: Get real-time feedback on speaking pace and tone
- **Presentation Practice**: Monitor your delivery during practice sessions
- **Communication Training**: Build awareness of speaking habits
- **Accessibility**: Real-time transcription for hearing assistance

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

Apache 2.0 with Commons Clause - see LICENSE file for details.

**Summary**: Free for personal, educational, and internal use. Commercial use (selling the software or offering it as a paid service) requires a separate commercial license.

## ğŸ™ Acknowledgments

- **Faster-Whisper**: High-performance speech recognition
- **Ollama**: Local LLM inference
- **BlackHole**: Virtual audio driver
- **PyAudio**: Audio I/O library
- **Rumps**: macOS menu bar apps in Python
